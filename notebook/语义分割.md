[toc]

## 语义分割难点

1. **分辨率下降**：CNN提取的特征平移不变性，这对分类任务很有用，但是对分割来说，希望原图目标移动后，其特征的响应也在移动，因此分辨率下降导致最后featrue map包含位置信息少。通常使用“跳跃连接”解决，即将包含位置信息的高分辨率特征和包含语义信息的低分辨率融合解决

2. **感受野小**：CNN下采样倍率一般比较小，所以随后featrue map上每个grid的感受野一般不大，这就意味着每个特征接收少部分其他像素的信息，这对大尺度的目标来说是非常不利的。通常使用“空洞卷积”解决，即在不加深网络的情况下提高感受野

3. **目标多尺度**：图片存在多尺度的目标，如果仅使用一种分辨率去做最后分类，对其他分辨率效果不佳。通常使用多尺度特征融合来解决，比如PSP、ASPP模块

4. **依赖距离短**：这和感受野的影响类似，但是即使感受野再大，也不能大过原图，所以像素之间的长程依赖还不够。通常使用“自注意力机制”去解决，比如构建特征的通道注意力、空间注意力去创建这种依赖。

	![img](https://pic1.zhimg.com/80/v2-c9d04551523baf3ebe11bb074b5ed718_720w.webp)

- **金字塔模型**：通过构建并融合多尺度特征，实现对不同尺度目标的分割，代表模型有 DeepLab 系列，PSPNet，DANet，APCNet
- **编码器-解码器**：使用 CNN 下采样提取特征，然后使用线性插值、反卷积、反池化操作实现上采样，并通过跳跃连接将高分辨率的位置信息联通到低分辨率的语义特征
- **“自注意力”系列**：通过引入“自注意力”机制，构建像素之间的远程连接，解决感受野解决不了的尺度问题

## 语义分割的上采样类型

语义分割在还原分辨率时，通常使用上采样，不同的上采样在速度、精度有不同区别

| 方法     | 描述                                                         | 优点           | 缺点                                 |
| -------- | ------------------------------------------------------------ | -------------- | ------------------------------------ |
| 线性插值 | 通过相邻的元素决定待插值点的值，如最近邻插值、线性插值、双3次线性插值 | 快速、无需学习 | -                                    |
| 反池化   | 记录池化时的激活位置，上采样时直接将值赋值给这个位置         | 无需学习       | 需要额外存储记录激活；上采样效果不好 |
| 反卷积   | 通过反卷积上采样                                             | 可以被学习优化 | 增加模型计算，有网格效应             |

## 评价指标



![img](https://pic4.zhimg.com/80/v2-13ee1a1f66d73d575602396b01b04a5b_720w.webp)

- 语义分割常使用 mIOU 作为统计指标，注意：**统计某类 TP、FP、FN 指标时，是针对所有图片的所有像素预测结果、而不是具体一张图片**

- 首先统计某个类别在所有图片上的累计 TP、FP、FN 像素数量、然后计算这个类别的 IOU ，再算所有类别的平均
	$$
	IOU = \frac{TP}{FP+TP+FN}
	$$

## FCN（Fully Convolutional Networks）

CNN在进行convolution和pooling过程中丢失了图像细节，即feature map size逐渐变小，所以不能很好地指出物体的具体轮廓、指出每个像素具体属于哪个物体，无法做到精确的分割。

语义分割需要判断图像每个像素点的类别，进行精确分割。**图像语义分割是像素级别！**

创新点：

1. **全卷积化(Fully Convolutional)**：用于解决逐像素(pixel-wise)的预测问题。通过将基础网络(例如VGG)最后面几个全连接层换成卷积层，可实现任意大小的图像输入，并且输出图像大小与输入相对应，因为全连接层获取的信息为一维信息，无法标识像素点的类别，不适用于分割；

2. ==**反卷积/转置卷积(deconvolution)**== ：上采样操作，**经==双线性插值==滤波器初始化的反卷积**，用于恢复图片尺寸，方便后续进行逐像素预测;

3. **跳跃结构(skip architecture)**：将不同层次的特征图像素对应==相加==（非拼接），用于融合高低层特征信息。通过跨层连接的结构，结合了网络浅层的细(fine-grain)粒度信息信息以及深层的粗糙(coarse)信息，以实现精准的分割任务。语义分割任务要同时进行语义识别和目标定位，对于传统网络而言，这是一对矛盾，因为网络设置的层数较少，目标位置信息丰富，但语义信息弱，反之，如果网络设置的层数多，则目标位置信息损失严重，但语义信息强。跨层连接结构(skip architecture)，将低层的目标位置信息强但语义信息弱的特征图和高层目标位置信息弱但语义信息强的特征图进行融合，以此来提升语义分割性能。

	**较浅**的卷积层感知域较小，学习到一些局部区域的特征；

	**较深**的卷积层感知域较大，学习到更加抽象一些的特征；

结构：

![img](https://img-blog.csdnimg.cn/img_convert/d0862cb3fb34e1caa3de6f1f5e194463.png#pic_center)

## SegNet



![SegNet:高效而精准的图像语义分割网络](https://picx.zhimg.com/70/v2-2902bf83e945c797f0b7540794294404_1440w.image?source=172ae18b&biz_tag=Post)

创新：
解码器使用在对应编码器的最大池化步骤中计算的**池化索引**（pooling indices）来执行非线性上采样，这与反卷积相比，减少了参数量和运算量，而且消除了==学习上采样的需要==。相比于跳跃结构，池化索引在尽可能精确的保留边界信息的同时，减小了参数量。

经上采样后的特征图是稀疏的，因此随后使用可训练的卷积核进行卷积操作，生成密集的特征图。![在这里插入图片描述](https://img-blog.csdnimg.cn/0afcb64febd349909cc66e0ca58966fc.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5L2V5aaC5Y2D5rO3,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

[SegNet:高效而精准的图像语义分割网络 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/685978087)

## Unet

- overlap-tile策略

- 随机弹性变形进行数据增强

	使用随机位移向量在粗略的3x3网格上生成平滑变形。在收缩路径的末端采用dropout也能得到隐式的数据增强。

- 使用了加权loss

![在这里插入图片描述](https://img-blog.csdnimg.cn/a7894847178b46b0b2c0836929a21f1e.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBASmt4enQxMzE0,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

误区：

​		FCN是通过特征图对应像素值的相加来融合特征的；

​		U-net通过通道数的拼接，这样可以形成更厚的特征，当然这样会更佳消耗显存；

效果：

**网络层越深得到的特征图，有着更大的视野域，浅层卷积关注纹理特征，深层网络关注本质的那种特征，所以深层浅层特征都是有格子的意义的；另外一点是通过反卷积得到的更大的尺寸的特征图的边缘，是缺少信息的，毕竟每一次下采样提炼特征的同时，也必然会损失一些边缘特征，而失去的特征并不能从上采样中找回，因此通过特征的拼接，来实现边缘特征的一个找回。**

训练数据量远远大于训练图像的数量，这使得网络在少量样本的情况下也能获得不变性和鲁棒性。

模型实现了很好的分割效果，但**只能处理 2D 图像**。

[U-Net 学习笔记_随机弹性形变-CSDN博客](https://blog.csdn.net/danica_zou/article/details/114923945#:~:text=2.随机弹性变形进行数据增强 采用平移、旋转，灰度变形进行数据增强。,而随机弹性形变是训练带有很少注释图像的分割网络的关键。 使用随机位移向量在粗略的3x3网格上生成平滑变形。 在收缩路径的末端采用dropout也能得到隐式的数据增强。)

[图像分割之Unet解析及实现代码_overlap-tile代码实现-CSDN博客](https://blog.csdn.net/weixin_43916138/article/details/121745142)

## Multi-scale context aggregation by dilated convolutions

1. 膨胀卷积Dilated Convolutions，**在不失去分辨率的情况下，增大感受野.**

![img](https://pic2.zhimg.com/v2-e5cb00cd5036fdb99f2034cd764f0761_r.jpg)

2. 多尺度信息聚合 Multi-scale context aggregation...

![img](https://pic1.zhimg.com/v2-e3e10a875884d51af03fa83cc99d9334_r.jpg)

3. Front end 前端

	用VGG-16用作**前端模块**。最后两个池化层和striding layer(作者把pooling和striding两个单词是一起用，其实也就是删去了最后两个stride=2的池化层)被完全去除，并插入上下文模块(就是在front-end后面加上**context module**)。另外，中间特征图的填充也被去除，作者仅将输入特征图填充了 33 的宽度。

## Deeplab v1

1. 去掉了VGG16最后的两个max pooling，不降低特征图的分辨率
2. 使用Atrous convolution（空洞卷积）
3. （Dense） CRF 全连接条件随机场作为后处理，恢复边界细节，达到准确定位效果（v3舍弃）
4. 附加输入图像和前四个最大池化层的每个输出到一个两层卷积，然后拼接到主网络的最后一层，达到 **多尺度预测** 效果。

上采样使用双线性采样。。

## Deeplab v2

改用ResNet-101，提出了ASPP空洞空间金字塔池化

论文中提出了语义分割中的三个挑战：

1. 由于池化和卷积而减少的特征分辨率。
2. 多尺度目标的存在。
3. 由于 DCNN 不变性而减少的定位准确率。

对于第一个挑战可以减少特征图下采样的次数，但是会增加计算量。
对于第二个挑战可以使用图像金字塔、空间金字塔等多尺度方法获取多尺度上下文信息。
对于第三个挑战可以使用跳跃连接或者引入条件随机场。

利用空洞卷积的优势，从==不同的尺度上==提取特征，在不同的分支采用不同的空洞率以获得多尺度图像表征。这么做的原因也很简单，因为相同的事物在同一张图或不同图像中存在尺度上的差异。

![img](https://img-blog.csdnimg.cn/20181220140225358.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2Zhbnh1ZWxpYW4=,size_16,color_FFFFFF,t_70#pic_center)

![img](https://img-blog.csdnimg.cn/20190326164616615.png)

## Deeplab v3

![img](https://img-blog.csdnimg.cn/20190402190228185.png)

key points:

- 在残差块中使用多网格方法（MultiGrid），从而引入不同的空洞率，即在模型后端多加几层不同 rate 的空洞卷积
- 在空洞空间金字塔池化模块中加入图像级（Image-level）特征，并且使用 BatchNormalization 技巧，加入到ASPP模块
- 具有不同 atrous rates 的 ASPP 能够有效的捕获多尺度信息。不过，论文发现，随着sampling rate的增加，有效filter特征权重(即有效特征区域，而不是补零区域的权重)的数量会变小，极端情况下，当空洞卷积的 rate 和 feature map 的大小一致时， 3×3 卷积会退化成 1×1 。为了保留较大视野的空洞卷积的同时解决这个问题，DeepLabv3 的 ASPP 加入了 全局池化层+conv1x1+双线性插值上采样 的模块
- [DeepLabV3网络简析_deeplabv3网络结构-CSDN博客](https://blog.csdn.net/qq_37541097/article/details/121797301)

## RefineNet（多路径细化网络）

对于编解码结构而言，所有层次的特征对语义分割都是有帮助的。高层次的特征用于识别图像中的语义信息，低层次的特征则有助于恢复高分辨率图像的边界细节，通过长程残差连接实现高分辨率预测。通过这种方式，能够直接利用较早卷积层的细粒度特征来精确调整捕获高级语义特征的深层。

![语义分割经典——RefineNet详解](https://picx.zhimg.com/70/v2-03f933467a5cc0546388c394f65a6f1b_1440w.image?source=172ae18b&biz_tag=Post)

每个编码器ResNet卷积块的输出特征图都会被连接到对应的RefineNet部分，ResNet-4连接到RefineNet-4，到了RefineNet-3，除了接收来自ResNet-3的输出外，还需要接收RefineNet-4的输出，对于RefineNet-3而言就构成了两路径的输入，这样层层向上级联，就构成了多路径的RefineNet。其中编码器中每个特征图到解码器RefineNet单元的连接也叫==长程残差连接==（long-range residual connections）。RefineNet block（块）的作用是把不同分辨率的特征图融合。

![img](https://img-blog.csdnimg.cn/20190719135529778.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQxOTk3OTIw,size_16,color_FFFFFF,t_70)

一个RefineNet单元由残差卷积单元（Residual convolution unit，RCU）、多分辨率融合（Multi-resolution Fusion）和链式残差池化（Chained Residual Pooling，CRP）以及Output convolutions输出这几个部分组成。除了RefineNet-4是单输入，其他全是二输入。

**残差卷积单元Residual convolution unit**

RCU是从残差网络中提取出来的单元结构，每一个输入路径都会经过两次RCU操作后再输出到下一个单元。RCU的跳跃连接在RefineNet中也被称为==短程残差连接==（short-range residual connections）。

**多分辨率特征图融合层Multi-resolution Fusion**

这是先对多输入的特征图都用一个卷积层进行自适应缩放，变道到最小的特征图的尺寸大小再上采样，最后对element-wise（相应像素）进行相加，得到合并后的特征图。但如果是像RefineNet-4 的单输入block这一部分就不用了。

**链式残差池化Chained Residual Pooling**

CRP也是RefineNet的特色结构，通过3个链式的池化和卷积残差组合来捕捉大图像区域的背景上下文信息。将CRP之后得到特征图再经过一次RCU即可到最终的分割输出。

卷积层作为之后加权求和的权重，ReLU对接下来池化的有效性很重要，而且使得模型对学习率的变化没这么敏感。这个链式结构能从很大范围区域上获取背景上下文信息。

另外，这个结构中大量使用了identity mapping （恒等变换）这样的连接，无论长距离或者短距离的，这样的结构允许梯度从一个block 直接向其他任一block 传播。

**Output convolutions**

其实就是输出前再加一个RCU。

key points：

- 使用**多分辨率**作为输入，将提取的特征融合在一起，并将其传递到下一个阶段。
- 引入**链式残差池化**，可以从一个大的图像区域获取背景信息。它通过多窗口尺寸有效地池化特性，利用残差连接和学习权重方式融合这些特征。
- 所有的特征融合都是使用sum（ResNet 方式）来进行端到端训练。
- 使用普通ResNet的残差层，**没有计算成本高的空洞卷积**。

[语义分割论文解读系列----RefineNet - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/609890719)

## PSP Net：Pyramid Scene Parsing Network

![img](https://img-blog.csdnimg.cn/20190402191224917.png)

key points：

- PSPNet 通过**引入空洞卷积来修改基础的 ResNet 架构**，特征经过最初的池化，在整个编码器网络中以相同的分辨率进行处理（原始图像输入的`1/4`），直到它到达空间池化模块。
- 在 ResNet 的中间层中引入**辅助损失**，以优化整体学习。
- 在修改后的 ResNet 编码器顶部的**空间金字塔池化**聚合全局上下文。

![img](https://img-blog.csdnimg.cn/20190402191049975.png)

在Spatial pyramid pooling中，不同层次的feature map在平滑和拼接之后被用于图像分类。这种先验信息是为了消除了CNN中固定尺寸的约束。为了进一步减少不同子区域之间的上下文信息丢失，我们提出了一种分层的全局先验信息，其中包含具有不同尺寸和在不同子区域之间变化的信息。这被称为**Pyramid Pooling Module**，用于在深度神经网络的最终层feature map上进行全局场景先验信息的构造，结构如上图。

金字塔池化（Pyramid pooling）融合了四个比例的特征。最粗糙的 1∗1 是全局尺度的池化，剩下的层次会将图像分为不同子区域，形成不同区域的信息表示。金字塔池模块中不同level的输出包含比例不同的feature map（比如输入的维度都是 2048 ，有四个层次的金字塔，那么输出的维度则为 2048/4=512 ）。为了保持全局特征的权重，若如果金字塔的数量为N，则在每个金字塔级别之后使用 1×1 卷积层将上下文表示的维度减小到原先的 1/N。然后直接对feature map进行双线性插值，恢复到输入的长宽上。最后，将不同level的特征拼接起来作为金字塔池化的全局特征。

![img](https://img-blog.csdnimg.cn/cdbf3d00897e42099c7888cc7563a2d1.png)

在PSPnet中，在Resnet的stage3最后一层的卷积处使用了辅助损失，是为了解决反向传播不能传递到浅层，加了辅助损失，两个损失都可以传递到之前的层，辅助损失优化了学习过程，主分支损失承担了主要的责任，且对辅助损失加了一个权重，在训练过程中我们使用辅助损失，在测试阶段我们不使用辅助损失，使用经过辅助损失优化好的网络。

![img](https://img-blog.csdnimg.cn/3b1dd717be3d4237941d30cacce20e70.png)

[[论文笔记\] PSPNet：Pyramid Scene Parsing Network - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/115004020)

## Link-Net

![image-20240314155359197](C:\Users\阿七\AppData\Roaming\Typora\typora-user-images\image-20240314155359197.png)

**创新之处便是在Encoder与Decoder的连接方式上**：

作者不仅将Encoder的输出作为Deocder的输入，还将Encoder的输入作为送入到Decoder。	

大小为`[H, W, n_channels]`的特征图先通过`1*1`卷积核得到大小为`[H, W, n_channels / 4]`的特征图，然后使用反卷积将其变为`[2*H, 2*W, n_channels / 4]`，最后使用`1*1`卷积使其大小变为`[2*H, 2*W, n_channels / 2]`，因此解码器有着更少的参数。

模型提高了速度又不失精度，可以在移动端实时分割

## E-Net

![img](https://img-blog.csdnimg.cn/img_convert/6112d0b653614e7b04d2d538622634ef.png)

![4d0c42df321b83b4ec16ee49679fbcab.png](https://img-blog.csdnimg.cn/img_convert/4d0c42df321b83b4ec16ee49679fbcab.png)

图(a)是initial模块，MaxPooling为步长2的2x2的filter，卷积有13个filter，Concat后的特征映射总计为16个，起到特征提取、压缩输入图像”体积”、除去图像中的视觉冗余信息的作用。图(b)是bottleneck 模块，采用残差连接的思想，包含三个卷积层：一个1 x 1的降维卷积，一个主卷积层，一个1 x 1扩张卷积，bn和PReLU放在中间。对于下采样的bottleneck模块，主分支添加最大池层，第一个1×1卷积被替换为步长为2的2×2卷积，中间的主卷积有三种可能的选择：Conv普通卷积,asymmetric分解卷积（如分解成 5 × 1 和 1 × 5 ），Dilated空洞卷积。对于正则化方式，使用了Spatial Dropout，在bottleneck 2.0之前p=0.01，之后p=0.1。由网络结构表格可以看到，初始阶段包含一个块，接着是阶段1由5个bottleneck 组成，而阶段2和阶段3具有相同的结构，阶段3在开始时没有对输入进行降采样。阶段1到3是编码器。阶段4和5属于解码器。

细节：

（1）为了减少内核调用和内存操作，没有在任何投影中使用bias，因为cuDNN会使用单独的内核进行卷积和bias相加。这种方式对准确性没有任何影响。

（2）在每个卷积层和随后的非线性之间，都使用了bn进行处理。

（3）在解码器中，用max unpooling代替max pooling，用无bias的spatial convolution代替padding。

（4）在最后一个上采样模块中，没有使用池化索引，因为初始块在输入帧的3个通道上操作，而最终输出具有C特征映射（对象类的数量）。

（5）出于性能原因，只在网络的最后一个模块设置一个完全卷积，仅这一项就占用了解码器处理时间的很大一部分。

设计选择：

 1、Feature map resolution：

  语义分割中的图像下采样有两个主要缺点：一是降低特征图的分辨率意味着丢失精确边缘形状等空间信息；二是全像素分割要求输出与输入具有相同的分辨率。这意味着进行了多少次下采样将需要同样次数的上采样，这将增加模型尺寸和计算成本。第一个问题在FCN中通过编码器生成的特征映射之间的add得到了解决，在SegNet中通过保存在max pooling层中选择的元素的索引，并使用它们在解码器中生成稀疏的上采样映射得到了解决。作者遵循SegNet方法，因为它减少了对内存需求。尽管如此，还是发现下采样会损害准确性，需要尽可能的限制下采样。当然，下采样能够扩大感受野，学习到更多的上下文特征用于逐像素的分类。

 2、Early downsampling：

  高分辨率的输入会耗费大量计算资源，ENet的初始化模块会大大减少输入图像的大小，并且只使用了少量的feature maps，初始化模块充当良好的特性提取器，并且只对网络稍后部分的输入进行预处理。

 3、Decoder size：

  ENet的Encoder和Decoder不对称，由一个较大的Encoder和一个较小的Decoder组成，作者认为Encoder和分类模型相似，主要进行特征信息的处理和过滤，而decoder主要是对encoder的输出做上采样，对细节做细微调。

4、Nonlinear operations：

  作者发现ENet上使用ReLU却降低了精度。相反，删除网络初始层中的大多数ReLU可以改善结果。用PReLU替换了网络中的所有ReLU，对每个特征映射PReLU有一个附加参数，目的是学习非线性的负斜率。

 5、Information-preserving dimensionality changes：

  选择在使用步长2的卷积的同时并行执行池化操作，并将得到的特征图拼接(concatenate)起来。这种技术可以将初始块的推理时间提高10倍。此外，在原始ResNet架构中发现了一个问题。下采样时，卷积分支中的第一个1×1卷积在两个维度上以2的步长滑动，直接丢弃了75%的输入。而ENet将卷积核的大小增加到了2×2，这样可以让整个输入都参与下采样，从而提高信息流和精度。虽然这使得这些层的计算成本增加了4倍，但是在ENET中这些层的数量很少，开销并不明显。

6、Factorizing filters：

  卷积权重存在大量冗余，并且每个n x n卷积可以分解成一个n x 1滤波和一个1 x n滤波，称为非对称卷积。本文采用n = 5的非对称卷积，它的操作相当于一个3 x 3的卷积，增加了模块的学习能力并增加了感受野，更重要的是，在瓶颈模块中使用的一系列操作(投影、卷积、投影)可以被视为将一个大卷积层分解为一系列更小和更简单的操作，即其低阶近似。这样的因子分解可以极大地减少参数的数量，从而减少冗余。此外，由于在层之间插入的非线性操作，特征也变得更丰富了。

7、Dilated convolutions：

大的感受野对分割任务也是非常重要的，可以参考更多的上下文特征对像素进行分类，为了避免对特征图进行过度的下采样，使用空洞卷积，在最小分辨率下运行的阶段中，几个瓶颈模块内的主要卷积层都使用了空洞卷积。在没有增加额外计算开销的情况下，便提高了准确度。当作者将空洞卷积与其他bottleneck（常规和非对称卷积）交织时，即不是按顺序排列它们，获得了最佳效果。

8、Regularization：

为了防止过拟合，把Spatial Dropout放在卷积分支的末端，就在加法之前。

[语义分割算法之ENet - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/93450275)

## G-FRNet

**网络结构**：

![img](https://img-blog.csdnimg.cn/2019040219143578.png)

1. 本文提出了一种门控反馈细化网络（G-FRNet），这是一种用于密集标记任务的端到端深度学习框架，可解决现有方法的这种局限性。
2. 首先G-FRNet进行粗略预测，然后在细化阶段有效地整合局部和全局上下文信息来逐步细化细节。
3. 本文引入了控制向前传递信息的门单元，以借助深层特征来辅助浅层特征滤除其中的信息的模糊与歧义。使用更深，更有辨别力的层的特征来过滤从辨别能力较差但定位更精细的早期层传递的信息。
4. 文章认为深层特征可以帮助浅层信息恢复特征中的模糊性内容，而单独的浅层信息并不能很好的恢复，因为其感受野不是很大或者并不具有足够的区分性。
5. 该模型的主要新颖之处在于，来自较早编码器层的信息在转发给解码器之前先经过门单元。 
6. 在将每个等级评分图传递到下一阶段的优化模块之前，我们使用标准的2x（两倍）双线性上采样。我们还使用下采样的地面真相标签图在每个解码阶段提供监视（l1，l2，...，l6）

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201011142934155.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FlcWprcWprbHE=,size_16,color_FFFFFF,t_70#pic_center)

![在这里插入图片描述](https://img-blog.csdnimg.cn/20201011142956416.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FlcWprcWprbHE=,size_16,color_FFFFFF,t_70#pic_center)

（这个单元的位置在l1，l2···，l6？）

采用深监督策略：

![image-20240315171029616](C:\Users\阿七\AppData\Roaming\Typora\typora-user-images\image-20240315171029616.png)

其中的η表示原始真值，这里的R表示放缩到对应的特征图大小后的真值。这里使用交叉熵，最终损失直接加和，权重都为1。

[语义分割之Gated Feedback Refinement Network for Dense Image Labeling_g-frnet: gated feedback refinement network for den-CSDN博客](https://blog.csdn.net/P_LarT/article/details/95238853)

[G-FRNet论文阅读_门控前向细化网络的多阶段时间卷积结构(g-frnet)-CSDN博客](https://blog.csdn.net/qeqjkqjklq/article/details/109011392)

## Deeplab v3+

网络架构：

![img](https://pic1.zhimg.com/v2-9949c7916b7d8fcf2b6a99e22f416c28_r.jpg)

它的Encoder的主体是带有空洞卷积的DCNN，可以采用常用的分类网络如ResNet，然后是带有空洞卷积的空间金字塔池化模块（Atrous Spatial Pyramid Pooling, ASPP)），主要是为了引入多尺度信息；相比DeepLabv3，v3+引入了Decoder模块，其将底层特征与高层特征进一步融合，提升分割边界准确度。从某种意义上看，DeepLabv3+在DilatedFCN基础上引入了EcoderDecoder的思路。

![img](https://img-blog.csdnimg.cn/20190402190228185.png)

对于DilatedFCN，主要是修改分类网络的后面block，用空洞卷积来替换stride=2的下采样层，其实这就是DeepLabv3结构，v3+只不过是增加了Decoder模块。这里的DCNN可以是任意的分类网络，一般又称为backbone，如采用ResNet网络。

backbone：

DeepLabv3所采用的backbone是ResNet网络，在v3+模型作者尝试了改进的Xception，Xception网络主要采用depthwise separable convolution，这使得Xception计算量更小。

采用改进的Xception网络作为backbone，DeepLab网络分割效果上有一定的提升。作者还尝试了在ASPP中加入depthwise separable convolution，发现在基本不影响模型效果的前提下减少计算量。

[语义分割模型之DeepLabv3+ - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/62261970)
